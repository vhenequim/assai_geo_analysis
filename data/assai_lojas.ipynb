{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import json\n",
    "from geopy.distance import great_circle\n",
    "import openrouteservice\n",
    "from openrouteservice import convert\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pl.read_json(r'data.json')\n",
    "df2 = pd.read_json(r'data.json')\n",
    "df_old_data = pl.read_excel(r'Lojas Assaí.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inaug22 = pl.read_csv('T2022.csv')\n",
    "df_inaug23 = pl.read_csv('T2023.csv')\n",
    "df_inaug24 = pl.read_csv('T2024.csv')\n",
    "df_inaug_data = pl.concat([\n",
    "    df_inaug24.rename({\"column_0\": \"value\"}),\n",
    "    df_inaug23.rename({\"column_0\": \"value\"}),\n",
    "    df_inaug22.rename({\"column_0\": \"value\"})\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_pipeline(dataf):\n",
    "    return dataf.clone()\n",
    "\n",
    "def drop_columns_new(dataf):\n",
    "    dataf = dataf.drop('url', 'subRegiao', 'subRegiaoTid', 'telefone', 'televendas', 'horario', 'email', 'ico_sust', 'voce_encontra', 'destaques', 'eslug', 'eid', 'e', 'tid', 'whatsapp', 'mapa', 'complemento', 'nid', 'cep', 'loja_id')\n",
    "    return dataf\n",
    "\n",
    "def drop_columns_old(dataf):\n",
    "    dataf = dataf.drop('Unnamed: 4', 'Código Município')\n",
    "    return dataf\n",
    "\n",
    "def strip_chars_new(dataf):\n",
    "    dataf = dataf.with_columns(pl.col(\"n\").str.strip_chars())\n",
    "    return dataf\n",
    "\n",
    "def strip_chars_old(dataf):\n",
    "    dataf = dataf.with_columns(pl.col(\"Unidade\").str.strip_chars())\n",
    "    return dataf\n",
    "\n",
    "def rename_columns(dataf):\n",
    "    dataf = dataf.rename({'n':'Unidade', 'c':'Município', 'uf':'UF', 'lat':'LAT', 'lon':'LONG', 'logradouro':'Endereço'})\n",
    "    dataf = dataf.cast({\"LAT\": pl.Float64, \"LONG\": pl.Float64})\n",
    "    return dataf\n",
    "\n",
    "def sort_columns(dataf):\n",
    "    dataf = dataf.select(['Unidade','Endereço','Município','UF','LAT','LONG'])\n",
    "    return dataf\n",
    "\n",
    "def format_names(dataf):\n",
    "    dataf = dataf.with_columns(\n",
    "        pl.col(\"value\")\n",
    "        .str.strip_chars()  # Remove trailing spaces\n",
    "        .str.replace(r\" - .*\", \"\", literal=False)  # Remove anything after the \"-\"\n",
    "        .str.to_lowercase()  # Convert to lowercase\n",
    "    )\n",
    "    return dataf\n",
    "\n",
    "def filter_tri(dataf):\n",
    "    dataf = dataf.filter(~pl.col(\"column_1\").is_in([\"1T2022\", \"2T2022\"]))\n",
    "    return dataf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (84, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>value</th><th>column_1</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;assaí vitória aeroporto&quot;</td><td>&quot;2T2024&quot;</td></tr><tr><td>&quot;assaí marginal tietê vila mari…</td><td>&quot;1T2024&quot;</td></tr><tr><td>&quot;assaí santa rosa&quot;</td><td>&quot;1T2024&quot;</td></tr><tr><td>&quot;assaí zona norte&quot;</td><td>&quot;1T2024&quot;</td></tr><tr><td>&quot;assaí cidade tiradentes&quot;</td><td>&quot;1T2024&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;assaí guaianases&quot;</td><td>&quot;3T2022&quot;</td></tr><tr><td>&quot;assaí araraquara&quot;</td><td>&quot;3T2022&quot;</td></tr><tr><td>&quot;assaí cabula&quot;</td><td>&quot;3T2022&quot;</td></tr><tr><td>&quot;assaí campina grande&quot;</td><td>&quot;3T2022&quot;</td></tr><tr><td>&quot;assaí ceilândia&quot;</td><td>&quot;3T2022&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (84, 2)\n",
       "┌─────────────────────────────────┬──────────┐\n",
       "│ value                           ┆ column_1 │\n",
       "│ ---                             ┆ ---      │\n",
       "│ str                             ┆ str      │\n",
       "╞═════════════════════════════════╪══════════╡\n",
       "│ assaí vitória aeroporto         ┆ 2T2024   │\n",
       "│ assaí marginal tietê vila mari… ┆ 1T2024   │\n",
       "│ assaí santa rosa                ┆ 1T2024   │\n",
       "│ assaí zona norte                ┆ 1T2024   │\n",
       "│ assaí cidade tiradentes         ┆ 1T2024   │\n",
       "│ …                               ┆ …        │\n",
       "│ assaí guaianases                ┆ 3T2022   │\n",
       "│ assaí araraquara                ┆ 3T2022   │\n",
       "│ assaí cabula                    ┆ 3T2022   │\n",
       "│ assaí campina grande            ┆ 3T2022   │\n",
       "│ assaí ceilândia                 ┆ 3T2022   │\n",
       "└─────────────────────────────────┴──────────┘"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (df_data\n",
    " .pipe(start_pipeline)\n",
    " .pipe(drop_columns_new)\n",
    " .pipe(strip_chars_new)\n",
    " .pipe(rename_columns)\n",
    " .pipe(sort_columns))\n",
    "\n",
    "df_old = (df_old_data\n",
    " .pipe(start_pipeline)\n",
    " .pipe(strip_chars_old)\n",
    " .pipe(drop_columns_old))\n",
    "\n",
    "df_inaug = (df_inaug_data\n",
    " .pipe(start_pipeline)\n",
    " .pipe(format_names)\n",
    " .pipe(filter_tri))\n",
    "\n",
    "df_inaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase columns\n",
    "df_lower = df.clone()\n",
    "df_old_lower = df_old.clone()\n",
    "\n",
    "# Check for intersection etc\n",
    "only_in_df1 = df.filter(~pl.col(\"Unidade\").str.to_lowercase().is_in(df_old['Unidade'].str.to_lowercase())).with_columns(pl.lit(\"Nova\").alias(\"status\"))\n",
    "only_in_df2 = df_old.filter(~pl.col('Unidade').str.to_lowercase().is_in(df[\"Unidade\"].str.to_lowercase())).with_columns(pl.lit(\"Fechou\").alias(\"status\"))\n",
    "common_in_both = df_old.filter(pl.col(\"Unidade\").str.to_lowercase().is_in(df['Unidade'].str.to_lowercase())).with_columns(pl.lit(\"Antigas\").alias(\"status\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the results \n",
    "df_diff = pl.concat([\n",
    "    only_in_df1.rename({\"Unidade\": \"value\"}),\n",
    "    only_in_df2.rename({\"Unidade\": \"value\"}),\n",
    "    common_in_both.rename({\"Unidade\": \"value\"})\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = df_diff.with_columns(\n",
    "    pl.col(\"value\").str.to_lowercase().alias(\"value_lower\")\n",
    ")\n",
    "\n",
    "# Ensure compatibility\n",
    "df_inaug = df_inaug.with_columns(pl.col(\"value\").cast(pl.Utf8))\n",
    "\n",
    "# Perform a left join to add `column_1` from df_inaug to df_diff based on the temporary lowercase column\n",
    "df_diff = df_diff.join(df_inaug, left_on=\"value_lower\", right_on=\"value\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = df_diff.with_columns(\n",
    "    pl.when(pl.col(\"column_1\").is_not_null())  # Check if 'column_1' exists after join\n",
    "    .then(pl.lit(\"Nova\"))  # Update status to 'Nova'\n",
    "    .otherwise(pl.col(\"status\"))  # Keep the original status otherwise\n",
    "    .alias(\"status\")\n",
    ")\n",
    "\n",
    "# Remove the temporary lowercase column after the join\n",
    "df_diff = df_diff.drop(\"value_lower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xlsxwriter.workbook.Workbook at 0x1dc2e5a46b0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.write_excel(r\"lojasAssai.xlsx\", worksheet='lojasSite')\n",
    "df_diff.write_excel(r\"lojasAssaiDiff_notcorrect.xlsx\", worksheet='lojasSite')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Mudar os valores de status para os corretos\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (298, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>value</th><th>Endereço</th><th>Município</th><th>UF</th><th>LAT</th><th>LONG</th><th>status</th><th>column_1</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Assaí Acrissul&quot;</td><td>&quot;Avenida Fábio Zahran, 7.919 Ja…</td><td>&quot;Campo Grande&quot;</td><td>&quot;MS&quot;</td><td>-20.48716</td><td>-54.622101</td><td>&quot;Antigas&quot;</td><td>null</td></tr><tr><td>&quot;Assaí Adélia Franco&quot;</td><td>&quot;Avenida Adélia Franco 3735 - A…</td><td>&quot;Aracaju&quot;</td><td>&quot;SE&quot;</td><td>-10.948019</td><td>-37.071057</td><td>&quot;Conversao&quot;</td><td>&quot;4T2022&quot;</td></tr><tr><td>&quot;Assaí Aeroporto Congonhas&quot;</td><td>&quot;Av Washington Luís, nº 5859, S…</td><td>&quot;São Paulo&quot;</td><td>&quot;SP&quot;</td><td>-23.630161</td><td>-46.668179</td><td>&quot;Nova&quot;</td><td>&quot;4T2022&quot;</td></tr><tr><td>&quot;Assaí Águia de Haia&quot;</td><td>&quot;Avenida Águia de Haia, 2.636 P…</td><td>&quot;São Paulo&quot;</td><td>&quot;SP&quot;</td><td>-23.538604</td><td>-46.479809</td><td>&quot;Antigas&quot;</td><td>null</td></tr><tr><td>&quot;Assaí Alcântara&quot;</td><td>&quot;Rua Doutor Alfredo Backer, 605…</td><td>&quot;São Gonçalo&quot;</td><td>&quot;RJ&quot;</td><td>-22.819909</td><td>-43.003935</td><td>&quot;Antigas&quot;</td><td>null</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Assaí Vila Sônia&quot;</td><td>&quot;Avenida Professor Francisco Mo…</td><td>&quot;São Paulo&quot;</td><td>&quot;SP&quot;</td><td>-23.591995</td><td>-46.731717</td><td>&quot;Antigas&quot;</td><td>null</td></tr><tr><td>&quot;Assaí Vitória Aeroporto&quot;</td><td>&quot;Av. Fernando Ferrari, 2870&quot;</td><td>&quot;Vitória&quot;</td><td>&quot;ES&quot;</td><td>-20.255622</td><td>-40.2894</td><td>&quot;Nova&quot;</td><td>&quot;2T2024&quot;</td></tr><tr><td>&quot;Assaí Vitória da Conquista&quot;</td><td>&quot;Avenida Anel de Contorno s/n F…</td><td>&quot;Vitória da Conquista&quot;</td><td>&quot;BA&quot;</td><td>-14.849299</td><td>-40.884204</td><td>&quot;Antigas&quot;</td><td>null</td></tr><tr><td>&quot;Assaí Washington Soares&quot;</td><td>&quot;Avenida Washington Soares, 5.6…</td><td>&quot;Fortaleza&quot;</td><td>&quot;CE&quot;</td><td>-3.807515</td><td>-38.479056</td><td>&quot;Antigas&quot;</td><td>null</td></tr><tr><td>&quot;Assaí Zona Norte&quot;</td><td>&quot;Rua Tancredo Neves, 528&quot;</td><td>&quot;Macapá&quot;</td><td>&quot;AP&quot;</td><td>0.06762</td><td>-51.05688</td><td>&quot;Nova&quot;</td><td>&quot;1T2024&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (298, 8)\n",
       "┌──────────────┬──────────────┬─────────────┬─────┬────────────┬────────────┬───────────┬──────────┐\n",
       "│ value        ┆ Endereço     ┆ Município   ┆ UF  ┆ LAT        ┆ LONG       ┆ status    ┆ column_1 │\n",
       "│ ---          ┆ ---          ┆ ---         ┆ --- ┆ ---        ┆ ---        ┆ ---       ┆ ---      │\n",
       "│ str          ┆ str          ┆ str         ┆ str ┆ f64        ┆ f64        ┆ str       ┆ str      │\n",
       "╞══════════════╪══════════════╪═════════════╪═════╪════════════╪════════════╪═══════════╪══════════╡\n",
       "│ Assaí        ┆ Avenida      ┆ Campo       ┆ MS  ┆ -20.48716  ┆ -54.622101 ┆ Antigas   ┆ null     │\n",
       "│ Acrissul     ┆ Fábio        ┆ Grande      ┆     ┆            ┆            ┆           ┆          │\n",
       "│              ┆ Zahran,      ┆             ┆     ┆            ┆            ┆           ┆          │\n",
       "│              ┆ 7.919 Ja…    ┆             ┆     ┆            ┆            ┆           ┆          │\n",
       "│ Assaí Adélia ┆ Avenida      ┆ Aracaju     ┆ SE  ┆ -10.948019 ┆ -37.071057 ┆ Conversao ┆ 4T2022   │\n",
       "│ Franco       ┆ Adélia       ┆             ┆     ┆            ┆            ┆           ┆          │\n",
       "│              ┆ Franco 3735  ┆             ┆     ┆            ┆            ┆           ┆          │\n",
       "│              ┆ - A…         ┆             ┆     ┆            ┆            ┆           ┆          │\n",
       "│ Assaí        ┆ Av           ┆ São Paulo   ┆ SP  ┆ -23.630161 ┆ -46.668179 ┆ Nova      ┆ 4T2022   │\n",
       "│ Aeroporto    ┆ Washington   ┆             ┆     ┆            ┆            ┆           ┆          │\n",
       "│ Congonhas    ┆ Luís, nº     ┆             ┆     ┆            ┆            ┆           ┆          │\n",
       "│              ┆ 5859, S…     ┆             ┆     ┆            ┆            ┆           ┆          │\n",
       "│ Assaí Águia  ┆ Avenida      ┆ São Paulo   ┆ SP  ┆ -23.538604 ┆ -46.479809 ┆ Antigas   ┆ null     │\n",
       "│ de Haia      ┆ Águia de     ┆             ┆     ┆            ┆            ┆           ┆          │\n",
       "│              ┆ Haia, 2.636  ┆             ┆     ┆            ┆            ┆           ┆          │\n",
       "│              ┆ P…           ┆             ┆     ┆            ┆            ┆           ┆          │\n",
       "│ Assaí        ┆ Rua Doutor   ┆ São Gonçalo ┆ RJ  ┆ -22.819909 ┆ -43.003935 ┆ Antigas   ┆ null     │\n",
       "│ Alcântara    ┆ Alfredo      ┆             ┆     ┆            ┆            ┆           ┆          │\n",
       "│              ┆ Backer, 605… ┆             ┆     ┆            ┆            ┆           ┆          │\n",
       "│ …            ┆ …            ┆ …           ┆ …   ┆ …          ┆ …          ┆ …         ┆ …        │\n",
       "│ Assaí Vila   ┆ Avenida      ┆ São Paulo   ┆ SP  ┆ -23.591995 ┆ -46.731717 ┆ Antigas   ┆ null     │\n",
       "│ Sônia        ┆ Professor    ┆             ┆     ┆            ┆            ┆           ┆          │\n",
       "│              ┆ Francisco    ┆             ┆     ┆            ┆            ┆           ┆          │\n",
       "│              ┆ Mo…          ┆             ┆     ┆            ┆            ┆           ┆          │\n",
       "│ Assaí        ┆ Av. Fernando ┆ Vitória     ┆ ES  ┆ -20.255622 ┆ -40.2894   ┆ Nova      ┆ 2T2024   │\n",
       "│ Vitória      ┆ Ferrari,     ┆             ┆     ┆            ┆            ┆           ┆          │\n",
       "│ Aeroporto    ┆ 2870         ┆             ┆     ┆            ┆            ┆           ┆          │\n",
       "│ Assaí        ┆ Avenida Anel ┆ Vitória da  ┆ BA  ┆ -14.849299 ┆ -40.884204 ┆ Antigas   ┆ null     │\n",
       "│ Vitória da   ┆ de Contorno  ┆ Conquista   ┆     ┆            ┆            ┆           ┆          │\n",
       "│ Conquista    ┆ s/n F…       ┆             ┆     ┆            ┆            ┆           ┆          │\n",
       "│ Assaí        ┆ Avenida      ┆ Fortaleza   ┆ CE  ┆ -3.807515  ┆ -38.479056 ┆ Antigas   ┆ null     │\n",
       "│ Washington   ┆ Washington   ┆             ┆     ┆            ┆            ┆           ┆          │\n",
       "│ Soares       ┆ Soares, 5.6… ┆             ┆     ┆            ┆            ┆           ┆          │\n",
       "│ Assaí Zona   ┆ Rua Tancredo ┆ Macapá      ┆ AP  ┆ 0.06762    ┆ -51.05688  ┆ Nova      ┆ 1T2024   │\n",
       "│ Norte        ┆ Neves, 528   ┆             ┆     ┆            ┆            ┆           ┆          │\n",
       "└──────────────┴──────────────┴─────────────┴─────┴────────────┴────────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diff = pl.read_excel(r\"lojasAssaiDiff_corrected.xlsx\")\n",
    "df_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom sort order\n",
    "status_order = [\"Nova\", \"Conversao\", \"Organica\", \"Ex Combo Extra\", \"Antigas\", \"Fechou\"]\n",
    "\n",
    "# Add a temporary column for sorting based on status_order using conditional expressions\n",
    "df_diff = df_diff.with_columns(\n",
    "    pl.when(pl.col(\"status\") == \"Nova\").then(0)\n",
    "    .when(pl.col(\"status\") == \"Conversao\").then(1)\n",
    "    .when(pl.col(\"status\") == \"Organica\").then(2)\n",
    "    .when(pl.col(\"status\") == \"Ex Combo Extra\").then(3)\n",
    "    .when(pl.col(\"status\") == \"Antigas\").then(4)\n",
    "    .when(pl.col(\"status\") == \"Fechou\").then(5)\n",
    "    .otherwise(-1)  # Assign -1 or any default value for unexpected statuses\n",
    "    .alias(\"status_order\")\n",
    ")\n",
    "\n",
    "# Sort the DataFrame by the temporary 'status_order' column\n",
    "df_diff = df_diff.sort(\"status_order\")\n",
    "\n",
    "# Drop the temporary sorting column as it's no longer needed\n",
    "df_diff = df_diff.drop(\"status_order\")\n",
    "\n",
    "# Separate the DataFrame into active and inactive stores\n",
    "active_statuses = [\"Nova\", \"Conversao\", \"Organica\", \"Ex Combo Extra\"]\n",
    "inactive_statuses = [\"Antigas\", \"Fechou\"]\n",
    "\n",
    "active_df = df_diff.filter(pl.col(\"status\").is_in(active_statuses))\n",
    "inactive_df = df_diff.filter(pl.col(\"status\").is_in(inactive_statuses))\n",
    "\n",
    "# Proceed with distance calculations only on active_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VHENEQUIM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openrouteservice\\client.py:211: UserWarning: Rate limit exceeded. Retrying for the 1st time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n",
      "c:\\Users\\VHENEQUIM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openrouteservice\\client.py:211: UserWarning: Rate limit exceeded. Retrying for the 2nd time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n",
      "c:\\Users\\VHENEQUIM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openrouteservice\\client.py:211: UserWarning: Rate limit exceeded. Retrying for the 3rd time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n",
      "c:\\Users\\VHENEQUIM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openrouteservice\\client.py:211: UserWarning: Rate limit exceeded. Retrying for the 4th time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n",
      "c:\\Users\\VHENEQUIM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openrouteservice\\client.py:211: UserWarning: Rate limit exceeded. Retrying for the 5th time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n",
      "c:\\Users\\VHENEQUIM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openrouteservice\\client.py:211: UserWarning: Rate limit exceeded. Retrying for the 6th time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n",
      "c:\\Users\\VHENEQUIM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openrouteservice\\client.py:211: UserWarning: Rate limit exceeded. Retrying for the 7th time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n",
      "c:\\Users\\VHENEQUIM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openrouteservice\\client.py:211: UserWarning: Rate limit exceeded. Retrying for the 8th time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n",
      "c:\\Users\\VHENEQUIM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openrouteservice\\client.py:211: UserWarning: Rate limit exceeded. Retrying for the 9th time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Function to calculate route with retries\n",
    "def calculate_route(client, coords, max_retries=5):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            route = client.directions(\n",
    "                [coords[0], coords[1]],\n",
    "                profile='driving-car',\n",
    "                format='geojson'\n",
    "            )\n",
    "            return route['features'][0]['geometry']['coordinates']\n",
    "        except openrouteservice.exceptions.ApiError as e:\n",
    "            if \"Rate limit exceeded\" in str(e):\n",
    "                wait_time = 2 ** attempt\n",
    "                print(f\"Rate limit exceeded. Retrying in {wait_time} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(f\"API error: {e}\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "            break\n",
    "    return None\n",
    "\n",
    "# Initialize the OpenRouteService client\n",
    "client = openrouteservice.Client(key=keys.API_OPENROUTESERVICE)\n",
    "\n",
    "# Create lists for the new columns, initialized with None for all rows\n",
    "closest_values_old = [None] * active_df.height\n",
    "closest_distances_old = [None] * active_df.height\n",
    "closest_values_old_LAT = [None] * active_df.height\n",
    "closest_values_old_LONG = [None] * active_df.height\n",
    "closest_values_all = [None] * active_df.height\n",
    "closest_distances_all = [None] * active_df.height\n",
    "route_geometries_old = [None] * active_df.height\n",
    "route_geometries_all = [None] * active_df.height\n",
    "\n",
    "# Iterate through each active row for distance calculations\n",
    "for index, row in enumerate(active_df.iter_rows(named=True)):\n",
    "    current_coords = (row[\"LAT\"], row[\"LONG\"])\n",
    "    \n",
    "    # Calculate distances to \"Antigas\" values\n",
    "    distances_old = [\n",
    "        (other_row[\"value\"], great_circle(current_coords, (other_row[\"LAT\"], other_row[\"LONG\"])).kilometers)\n",
    "        for other_row in inactive_df.iter_rows(named=True)\n",
    "    ]\n",
    "    \n",
    "    # Find the closest \"Antigas\" value\n",
    "    if distances_old:\n",
    "        closest_value_old, min_distance_old = min(distances_old, key=lambda x: x[1])\n",
    "        closest_coords_old = next(row for row in inactive_df.iter_rows(named=True) if row[\"value\"] == closest_value_old)\n",
    "        closest_values_old[index] = closest_value_old\n",
    "        closest_distances_old[index] = min_distance_old\n",
    "        closest_values_old_LAT[index] = closest_coords_old[\"LAT\"]\n",
    "        closest_values_old_LONG[index] = closest_coords_old[\"LONG\"]\n",
    "    \n",
    "    # Calculate distances to all other active values\n",
    "    distances_all = [\n",
    "        (other_row[\"value\"], great_circle(current_coords, (other_row[\"LAT\"], other_row[\"LONG\"])).kilometers)\n",
    "        for other_row in active_df.iter_rows(named=True)\n",
    "        if other_row[\"value\"] != row[\"value\"]  # Skip itself\n",
    "    ]\n",
    "    \n",
    "    # Find the closest value among all active stores\n",
    "    if distances_all:\n",
    "        closest_value_all, min_distance_all = min(distances_all, key=lambda x: x[1])\n",
    "        closest_values_all[index] = closest_value_all\n",
    "        closest_distances_all[index] = min_distance_all\n",
    "    \n",
    "    # Calculate route for closest \"Antigas\" store with retries\n",
    "    if closest_values_old[index]:\n",
    "        route_old = calculate_route(\n",
    "            client, \n",
    "            [(row[\"LONG\"], row[\"LAT\"]), (closest_values_old_LONG[index], closest_values_old_LAT[index])]\n",
    "        )\n",
    "        route_geometries_old[index] = route_old\n",
    "    \n",
    "    # Calculate route for closest store among all active with retries\n",
    "    if closest_values_all[index]:\n",
    "        closest_coords_all = active_df.filter(pl.col(\"value\") == closest_values_all[index]).select([\"LONG\", \"LAT\"]).to_dicts()[0]\n",
    "        route_all = calculate_route(\n",
    "            client, \n",
    "            [(row[\"LONG\"], row[\"LAT\"]), (closest_coords_all[\"LONG\"], closest_coords_all[\"LAT\"])]\n",
    "        )\n",
    "        route_geometries_all[index] = route_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new columns to active_df\n",
    "active_df = active_df.with_columns([\n",
    "    pl.Series(\"closest_value_old\", closest_values_old),\n",
    "    pl.Series(\"closest_distance_old\", closest_distances_old),\n",
    "    pl.Series(\"closest_value_old_LAT\", closest_values_old_LAT),\n",
    "    pl.Series(\"closest_value_old_LONG\", closest_values_old_LONG),\n",
    "    pl.Series(\"closest_value_all\", closest_values_all),\n",
    "    pl.Series(\"closest_distance_all\", closest_distances_all),\n",
    "    pl.Series(\"route_geometry_old\", route_geometries_old),\n",
    "    pl.Series(\"route_geometry_all\", route_geometries_all)\n",
    "])\n",
    "\n",
    "# List of new columns added to active_df\n",
    "new_columns = [\n",
    "    \"closest_value_old\",\n",
    "    \"closest_distance_old\",\n",
    "    \"closest_value_old_LAT\",\n",
    "    \"closest_value_old_LONG\",\n",
    "    \"closest_value_all\",\n",
    "    \"closest_distance_all\",\n",
    "    \"route_geometry_old\",\n",
    "    \"route_geometry_all\"\n",
    "]\n",
    "\n",
    "# Add missing columns to inactive_df with null values\n",
    "inactive_df = inactive_df.with_columns([\n",
    "    pl.lit(None).alias(\"closest_value_old\"),\n",
    "    pl.lit(None).alias(\"closest_distance_old\"),\n",
    "    pl.lit(None).alias(\"closest_value_old_LAT\"),\n",
    "    pl.lit(None).alias(\"closest_value_old_LONG\"),\n",
    "    pl.lit(None).alias(\"closest_value_all\"),\n",
    "    pl.lit(None).alias(\"closest_distance_all\"),\n",
    "    pl.lit(None).alias(\"route_geometry_old\"),\n",
    "    pl.lit(None).alias(\"route_geometry_all\")\n",
    "])\n",
    "\n",
    "# Combine active_df and inactive_df back into df_diff\n",
    "df_diff = pl.concat([active_df, inactive_df], rechunk=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map with Polars-compatible search functionality has been saved as 'localizacoesAssai_with_polars_search.html'\n",
      "Please open this file in a web browser and check the browser's console for debugging information.\n"
     ]
    }
   ],
   "source": [
    "# Define color_map if not already defined\n",
    "# Example:\n",
    "color_map = {\n",
    "    \"Nova\": \"#4CAF50\",      # Softer green\n",
    "    \"Conversao\": \"#64B5F6\",  # Light blue\n",
    "    \"Organica\": \"#FFB74D\",   # Muted orange\n",
    "    \"Ex Combo Extra\": \"#9575CD\",  # Soft purple\n",
    "    \"Antigas\": \"#BDBDBD\",    # Light grey\n",
    "    \"Fechou\": \"#EF9A9A\"      # Light red\n",
    "}\n",
    "\n",
    "df_pandas = df_diff\n",
    "# Add a dummy column for size with all values set to 1\n",
    "df_pandas = df_pandas.with_columns(pl.lit(1).alias(\"dummy_column_for_size\"))\n",
    "\n",
    "# Ensure color_map is defined\n",
    "if 'color_map' not in locals():\n",
    "    color_map = {\n",
    "        \"Nova\": \"green\",\n",
    "        \"Conversao\": \"blue\",\n",
    "        \"Organica\": \"orange\",\n",
    "        \"Ex Combo Extra\": \"purple\",\n",
    "        \"Antigas\": \"red\",\n",
    "        \"Fechou\": \"grey\"\n",
    "    }\n",
    "\n",
    "# Create the scatter mapbox figure\n",
    "fig = px.scatter_mapbox(\n",
    "    df_pandas, \n",
    "    lat=\"LAT\", \n",
    "    lon=\"LONG\", \n",
    "    hover_name=\"value\",\n",
    "    hover_data={'status': True, 'LAT': True, 'LONG': True},\n",
    "    zoom=4,\n",
    "    height=600,\n",
    "    color='status',\n",
    "    color_discrete_map=color_map,\n",
    "    size='dummy_column_for_size',\n",
    "    size_max=10,\n",
    ")\n",
    "\n",
    "# Update hover information\n",
    "fig.update_traces(\n",
    "    hovertemplate=(\n",
    "        '%{hovertext}<br>'\n",
    "        'Status: %{marker.color}<br>'\n",
    "        'Latitude: %{lat}<br>'\n",
    "        'Longitude: %{lon}<br>'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add lines for closest \"Antigas\" stores\n",
    "lines = []\n",
    "for idx, row in enumerate(df_diff.iter_rows(named=True)):\n",
    "    if (row['status'] in active_statuses and \n",
    "        row['closest_value_old_LAT'] is not None and \n",
    "        row['closest_value_old_LONG'] is not None):\n",
    "        lines.append(go.Scattermapbox(\n",
    "            mode=\"lines\",\n",
    "            lon=[row['LONG'], row['closest_value_old_LONG']],\n",
    "            lat=[row['LAT'], row['closest_value_old_LAT']],\n",
    "            marker={'size': 1},\n",
    "            line=dict(width=2, color=color_map.get(row['status'], 'grey')),\n",
    "            hoverinfo='none',\n",
    "            showlegend=False\n",
    "        ))\n",
    "\n",
    "# Add all lines to the figure at once\n",
    "if lines:\n",
    "    fig.add_traces(lines)\n",
    "\n",
    "# Add route lines\n",
    "route_lines = []\n",
    "for row in df_diff.iter_rows(named=True):\n",
    "    if row['route_geometry_old']:\n",
    "        route_coords = row['route_geometry_old']\n",
    "        try:\n",
    "            lons, lats = zip(*route_coords)\n",
    "            route_lines.append(go.Scattermapbox(\n",
    "                mode=\"lines\",\n",
    "                lon=lons,\n",
    "                lat=lats,\n",
    "                line=dict(width=2, color=color_map.get(row['status'], 'grey')),\n",
    "                hoverinfo='none',\n",
    "                showlegend=False\n",
    "            ))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing route coordinates: {e}\")\n",
    "\n",
    "# Add all route lines to the figure\n",
    "if route_lines:\n",
    "    fig.add_traces(route_lines)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    autosize=True,\n",
    "    height=1080,\n",
    "    margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0}\n",
    ")\n",
    "\n",
    "# Convert the figure to JSON for HTML embedding\n",
    "plot_json = json.dumps(fig, cls=plotly.utils.PlotlyJSONEncoder)\n",
    "\n",
    "# Prepare the data for search functionality (only active stores)\n",
    "search_data = active_df.select(['LAT', 'LONG', 'value', 'status']).to_dicts()\n",
    "search_data_json = json.dumps(search_data)\n",
    "\n",
    "# Create HTML content with embedded Plotly figure and search functionality\n",
    "html_content = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "    <style>\n",
    "        #search-container {{\n",
    "            position: absolute;\n",
    "            top: 10px;\n",
    "            left: 10px;\n",
    "            z-index: 1000;\n",
    "            background-color: white;\n",
    "            padding: 10px;\n",
    "            border-radius: 5px;\n",
    "            box-shadow: 0 2px 5px rgba(0,0,0,0.2);\n",
    "        }}\n",
    "        #search-input {{\n",
    "            padding: 5px;\n",
    "            width: 200px;\n",
    "            margin-bottom: 5px;\n",
    "        }}\n",
    "        #search-results {{\n",
    "            max-height: 200px;\n",
    "            overflow-y: auto;\n",
    "            border: 1px solid #ccc;\n",
    "            display: none;\n",
    "            background-color: white;\n",
    "        }}\n",
    "        .result-item {{\n",
    "            padding: 5px;\n",
    "            cursor: pointer;\n",
    "        }}\n",
    "        .result-item:hover {{\n",
    "            background-color: #f0f0f0;\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div id=\"search-container\">\n",
    "        <input type=\"text\" id=\"search-input\" placeholder=\"Search for a store...\">\n",
    "        <div id=\"search-results\"></div>\n",
    "    </div>\n",
    "    <div id=\"mapDiv\"></div>\n",
    "\n",
    "    <script>\n",
    "        var plotlyData = {plot_json};\n",
    "        var searchData = {search_data_json};\n",
    "        \n",
    "        Plotly.newPlot('mapDiv', plotlyData.data, plotlyData.layout);\n",
    "\n",
    "        var searchInput = document.getElementById('search-input');\n",
    "        var searchResults = document.getElementById('search-results');\n",
    "\n",
    "        searchInput.addEventListener('input', function() {{\n",
    "            var searchTerm = this.value.toLowerCase();\n",
    "            \n",
    "            var results = searchData.filter(function(point) {{\n",
    "                return point.value.toLowerCase().includes(searchTerm);\n",
    "            }});\n",
    "            \n",
    "            displayResults(results);\n",
    "        }});\n",
    "\n",
    "        function displayResults(results) {{\n",
    "            searchResults.innerHTML = '';\n",
    "            if (results.length > 0) {{\n",
    "                results.forEach(function(result) {{\n",
    "                    var div = document.createElement('div');\n",
    "                    div.className = 'result-item';\n",
    "                    div.textContent = result.value + ' (' + result.status + ')';\n",
    "                    div.onclick = function() {{ \n",
    "                        centerOnPoint(result.LAT, result.LONG);\n",
    "                        searchInput.value = result.value;\n",
    "                        hideSearchResults();\n",
    "                    }};\n",
    "                    searchResults.appendChild(div);\n",
    "                }});\n",
    "                searchResults.style.display = 'block';\n",
    "            }} else {{\n",
    "                hideSearchResults();\n",
    "            }}\n",
    "        }}\n",
    "\n",
    "        function centerOnPoint(lat, lon) {{\n",
    "            Plotly.relayout('mapDiv', {{\n",
    "                'mapbox.center': {{ lat: lat, lon: lon }},\n",
    "                'mapbox.zoom': 15\n",
    "            }});\n",
    "        }}\n",
    "\n",
    "        function hideSearchResults() {{\n",
    "            searchResults.style.display = 'none';\n",
    "        }}\n",
    "\n",
    "        // Hide search results when clicking outside\n",
    "        document.addEventListener('click', function(event) {{\n",
    "            var searchContainer = document.getElementById('search-container');\n",
    "            if (!searchContainer.contains(event.target)) {{\n",
    "                hideSearchResults();\n",
    "            }}\n",
    "        }});\n",
    "\n",
    "        // Hide search results when pressing Esc key\n",
    "        document.addEventListener('keydown', function(event) {{\n",
    "            if (event.key === 'Escape') {{\n",
    "                hideSearchResults();\n",
    "            }}\n",
    "        }});\n",
    "\n",
    "        // Prevent hiding when clicking inside the search container\n",
    "        var searchContainer = document.getElementById('search-container');\n",
    "        searchContainer.addEventListener('click', function(event) {{\n",
    "            event.stopPropagation();\n",
    "        }});\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Write the HTML content to a file\n",
    "with open(\"localizacoesAssai_with_polars_search.html\", \"w\") as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "print(\"Map with Polars-compatible search functionality has been saved as 'localizacoesAssai_with_polars_search.html'\")\n",
    "print(\"Please open this file in a web browser and check the browser's console for debugging information.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
